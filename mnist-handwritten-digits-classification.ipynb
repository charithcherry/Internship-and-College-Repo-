{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms, datasets\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = torchvision.datasets.MNIST('', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.ToTensor()\n                       ]))\n\ntest = torchvision.datasets.MNIST('', train=False, download=True,\n                       transform=transforms.Compose([\n                           transforms.ToTensor()\n                       ]))\n\ntrainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True, num_workers=2)\n\ntestset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False, num_workers=2)","execution_count":2,"outputs":[{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5663fd1327ab4d16b7087c625eaae1a7"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d52c8a234230421b94f93363fad82d51"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b46aacc677fb4d8c93a1665953bb2a7f"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dfcc3a3416842c0acf1e60f8400f82a"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset_shape = trainset.dataset.train_data.shape\ntestset_shape = testset.dataset.test_data.shape\n\nprint(trainset_shape, testset_shape)","execution_count":3,"outputs":[{"output_type":"stream","text":"torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n  warnings.warn(\"train_data has been renamed data\")\n/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n  warnings.warn(\"test_data has been renamed data\")\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28*28, 64)\n        self.fc2 = nn.Linear(64, 64)\n        self.fc3 = nn.Linear(64, 64)\n        self.fc4 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return F.log_softmax(x, dim=1)   ","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()\nprint(net)","execution_count":5,"outputs":[{"output_type":"stream","text":"Net(\n  (fc1): Linear(in_features=784, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=64, bias=True)\n  (fc4): Linear(in_features=64, out_features=10, bias=True)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.005)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(5): \n    for data in trainset:  \n        X, y = data  \n        net.zero_grad()  \n        output = net(X.view(-1,784))  \n        loss = criterion(output, y)  \n        loss.backward()  \n        optimizer.step()  \n    print(loss)  \n","execution_count":8,"outputs":[{"output_type":"stream","text":"tensor(0.0287, grad_fn=<NllLossBackward>)\ntensor(0.0268, grad_fn=<NllLossBackward>)\ntensor(0.2007, grad_fn=<NllLossBackward>)\ntensor(0.0114, grad_fn=<NllLossBackward>)\ntensor(0.2198, grad_fn=<NllLossBackward>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\n\nwith torch.no_grad():\n    for data in testset:\n        X, y = data\n        output = net(X.view(-1,784))\n        \n        for idx, i in enumerate(output):\n               if torch.argmax(i) == y[idx]:\n                correct += 1\n                total += 1\n\nprint(\"Accuracy: \", round(correct/total, 2))","execution_count":10,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"unindent does not match any outer indentation level (<tokenize>, line 12)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    total += 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}