{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "sklearn-sentiment-analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charithcherry/Internship-and-College-Repo-/blob/master/ML%20Ground/MLOPS/BentoML/scikit-learn/sentiment-analysis/sklearn-sentiment-analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl-pmGX0zxij"
      },
      "source": [
        "# BentoML Example: Sentiment Analysis with Scikit-learn\n",
        "\n",
        "**BentoML makes moving trained ML models to production easy:**\n",
        "\n",
        "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
        "* **Deploy anywhere** for online API serving or offline batch serving\n",
        "* High-Performance API model server with *adaptive micro-batching* support\n",
        "* Central hub for managing models and deployment process via Web UI and APIs\n",
        "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
        "\n",
        "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
        "\n",
        "Before reading this example project, be sure to check out the [Getting started guide](https://github.com/bentoml/BentoML/blob/master/guides/quick-start/bentoml-quick-start-guide.ipynb) to learn about the basic concepts in BentoML.\n",
        "\n",
        "This notebook demonstrates how to use BentoML to turn a scikit-learn model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
        "\n",
        "\n",
        "*The example is based on [this notebook](https://github.com/crawles/sentiment_analysis_twitter_model/blob/master/build-sentiment-classifier.ipynb), using dataset from [Sentiment140](http://help.sentiment140.com/for-students/)*\n",
        "\n",
        "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=scikit-learn&ea=scikit-learn-sentiment-analysis&dt=scikit-learn-sentiment-analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmnJdiOAzxim"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC7uESNGzxin",
        "outputId": "03c51ab2-f5a5-4ec6-8a0e-63efc3dbf425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q bentoml 'scikit-learn>=0.23.2' 'pandas>=1.1.1' 'numpy>=1.8.2'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.0 MB 13.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 36 kB/s \n",
            "\u001b[K     |████████████████████████████████| 108 kB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 38.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 56.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 50.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 48.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 546 kB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 28.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 52.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
            "\u001b[?25h  Building wheel for sqlalchemy-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cerberus (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEmhzjvrzxio"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import bentoml"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm1NiYW5zxip"
      },
      "source": [
        "## Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Bor_8qzxiq",
        "outputId": "1c820c42-87a6-40d9-8bdc-bda31d18f5b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f ./trainingandtestdata.zip ]; then\n",
        "    wget -q http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
        "    unzip -n trainingandtestdata.zip\n",
        "fi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  trainingandtestdata.zip\n",
            "  inflating: testdata.manual.2009.06.14.csv  \n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TJ1we27zxir"
      },
      "source": [
        "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
        "dftrain = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
        "                      header = None,\n",
        "                      encoding ='ISO-8859-1')\n",
        "dftest = pd.read_csv('testdata.manual.2009.06.14.csv',\n",
        "                     header = None,\n",
        "                     encoding ='ISO-8859-1')\n",
        "dftrain.columns = columns\n",
        "dftest.columns = columns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQl9RurG3o8k",
        "outputId": "019a4fad-198f-4928-b86c-557e5dd885d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dftrain[dftrain.polarity==0].text"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1         is upset that he can't update his Facebook by ...\n",
              "2         @Kenichan I dived many times for the ball. Man...\n",
              "3           my whole body feels itchy and like its on fire \n",
              "4         @nationwideclass no, it's not behaving at all....\n",
              "                                ...                        \n",
              "799995    Sick  Spending my day laying in bed listening ...\n",
              "799996                                      Gmail is down? \n",
              "799997                        rest in peace Farrah! So sad \n",
              "799998    @Eric_Urbane Sounds like a rival is flagging y...\n",
              "799999    has to resit exams over summer...  wishes he w...\n",
              "Name: text, Length: 800000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi7Vf6o6zxis"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xJ15dyqrzxit",
        "outputId": "ce317938-0aff-49e4-9402-b30b7abc7d01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentiment_lr = Pipeline([\n",
        "                         ('count_vect', CountVectorizer(min_df = 100,\n",
        "                                                        ngram_range = (1,2),\n",
        "                                                        stop_words = 'english')), \n",
        "                         ('lr', LogisticRegression())])\n",
        "sentiment_lr.fit(dftrain.text, dftrain.polarity)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('count_vect',\n",
              "                 CountVectorizer(min_df=100, ngram_range=(1, 2),\n",
              "                                 stop_words='english')),\n",
              "                ('lr', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-okOgozYzxiu",
        "outputId": "35596bb2-8287-4c73-aaf1-40d18c7b4eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xtest, ytest = dftest.text[dftest.polarity!=2], dftest.polarity[dftest.polarity!=2]\n",
        "print(classification_report(ytest,sentiment_lr.predict(Xtest)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.82      0.84       177\n",
            "           4       0.83      0.88      0.86       182\n",
            "\n",
            "    accuracy                           0.85       359\n",
            "   macro avg       0.85      0.85      0.85       359\n",
            "weighted avg       0.85      0.85      0.85       359\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0lBLurpzxiv",
        "outputId": "9a61f5e2-beee-4880-c33c-c87bffcc39a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentiment_lr.predict([Xtest[11]])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOan5eFo48TR",
        "outputId": "9006e5b0-159a-49a5-f671-7f50be3260f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Xtest[11]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@Karoli I firmly believe that Obama/Pelosi have ZERO desire to be civil.  It's a charade and a slogan, but they want to destroy conservatism\""
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwfEc8K8zxiw"
      },
      "source": [
        "## Create BentoService for model serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YZ9EXkJDzxiw",
        "outputId": "633eeaa4-d9de-4b14-af9d-51ecfc19e2c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile sentiment_analysis_service.py\n",
        "import pandas as pd\n",
        "import bentoml\n",
        "from bentoml.frameworks.sklearn import SklearnModelArtifact\n",
        "from bentoml.service.artifacts.common import PickleArtifact\n",
        "from bentoml.handlers import DataframeHandler\n",
        "from bentoml.adapters import DataframeInput\n",
        "\n",
        "@bentoml.artifacts([PickleArtifact('model')])\n",
        "@bentoml.env(pip_packages=[\"scikit-learn\", \"pandas\"])\n",
        "class SKSentimentAnalysis(bentoml.BentoService):\n",
        "\n",
        "    @bentoml.api(input=DataframeInput(), batch=True)\n",
        "    def predict(self, df):\n",
        "        \"\"\"\n",
        "        predict expects pandas.Series as input\n",
        "        \"\"\"        \n",
        "        series = df.iloc[0,:]\n",
        "        return self.artifacts.model.predict(series)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing sentiment_analysis_service.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j-IfWNrzxix"
      },
      "source": [
        "## Save BentoService to file archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5VyT_5Gzxix",
        "outputId": "f10eeefc-1c2c-413f-9cee-be0f1ea069b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 1) import the custom BentoService defined above\n",
        "from sentiment_analysis_service import SKSentimentAnalysis\n",
        "\n",
        "# 2) `pack` it with required artifacts\n",
        "bento_service = SKSentimentAnalysis()\n",
        "bento_service.pack('model', sentiment_lr)\n",
        "\n",
        "# 3) save your BentoSerivce to file archive\n",
        "saved_path = bento_service.save()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-08-26 09:37:09,124] WARNING - bentoml.handlers.* will be deprecated after BentoML 1.0, use bentoml.adapters.* instead\n",
            "[2021-08-26 09:37:09,609] WARNING - pip package requirement `bentoml==0.13.1` not found in current python environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2021-08-26 09:37:36,474] INFO - BentoService bundle 'SKSentimentAnalysis:20210826093710_6B5E44' saved to: /root/bentoml/repository/SKSentimentAnalysis/20210826093710_6B5E44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBQCKjt3zxiy"
      },
      "source": [
        "## REST API Model Serving\n",
        "\n",
        "\n",
        "To start a REST API model server with the BentoService saved above, use the bentoml serve command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ojiw7IHCzxiy",
        "outputId": "3aa432ea-d17b-46cd-9446-50586ce6bb4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!bentoml serve SKSentimentAnalysis:latest"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-08-26 09:40:03,318] INFO - Getting latest version SKSentimentAnalysis:20210826093710_6B5E44\n",
            "[2021-08-26 09:40:03,331] INFO - Starting BentoML API proxy in development mode..\n",
            "[2021-08-26 09:40:03,333] INFO - Starting BentoML API server in development mode..\n",
            "[2021-08-26 09:40:03,564] INFO - Micro batch enabled for API `predict` max-latency: 20000 max-batch-size 4000\n",
            "[2021-08-26 09:40:03,564] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
            "======== Running on http://0.0.0.0:5000 ========\n",
            "(Press CTRL+C to quit)\n",
            "[2021-08-26 09:40:03,721] WARNING - bentoml.handlers.* will be deprecated after BentoML 1.0, use bentoml.adapters.* instead\n",
            " * Serving Flask app \"SKSentimentAnalysis\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            " * Running on http://127.0.0.1:33651/ (Press CTRL+C to quit)\n",
            "\n",
            "Aborted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2rh9Ls_zxiy"
      },
      "source": [
        "If you are running this notebook from Google Colab, you can start the dev server with `--run-with-ngrok` option, to gain acccess to the API endpoint via a public endpoint managed by [ngrok](https://ngrok.com/):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XNnxFmfzxiz",
        "outputId": "f575c2eb-1d56-4b06-d670-6dbca334ac29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!bentoml serve SKSentimentAnalysis:latest --run-with-ngrok"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-08-26 09:56:53,153] INFO - Getting latest version SKSentimentAnalysis:20210826093710_6B5E44\n",
            "[2021-08-26 09:56:53,169] INFO - Starting BentoML API proxy in development mode..\n",
            "[2021-08-26 09:56:53,171] INFO - Starting BentoML API server in development mode..\n",
            "[2021-08-26 09:56:53,413] INFO - Micro batch enabled for API `predict` max-latency: 20000 max-batch-size 4000\n",
            "[2021-08-26 09:56:53,413] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
            "======== Running on http://0.0.0.0:5000 ========\n",
            "(Press CTRL+C to quit)\n",
            "[2021-08-26 09:56:53,571] WARNING - bentoml.handlers.* will be deprecated after BentoML 1.0, use bentoml.adapters.* instead\n",
            "[2021-08-26 09:56:55,181] INFO -  * Running on http://70a5-35-187-174-139.ngrok.io\n",
            "[2021-08-26 09:56:55,182] INFO -  * Traffic stats available on http://127.0.0.1:4040\n",
            " * Serving Flask app \"SKSentimentAnalysis\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            " * Running on http://127.0.0.1:49831/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:01] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:02] \"\u001b[37mGET /static_content/main.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:02] \"\u001b[37mGET /static_content/readme.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:02] \"\u001b[37mGET /static_content/swagger-ui.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:02] \"\u001b[37mGET /static_content/marked.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:02] \"\u001b[37mGET /static_content/swagger-ui-bundle.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:03] \"\u001b[37mGET /docs.json HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:03] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:03] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:05] \"\u001b[37mGET /static_content/marked.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:05] \"\u001b[37mGET /static_content/swagger-ui-bundle.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:05] \"\u001b[37mGET /static_content/main.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:05] \"\u001b[37mGET /static_content/swagger-ui.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:05] \"\u001b[37mGET /static_content/readme.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:09] \"\u001b[37mGET /docs.json HTTP/1.1\u001b[0m\" 200 -\n",
            "[2021-08-26 09:57:18,100] ERROR - Error caught in API function:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/bentoml/service/inference_api.py\", line 176, in wrapped_func\n",
            "    return self._user_func(*args, **kwargs)\n",
            "  File \"/root/bentoml/repository/SKSentimentAnalysis/20210826093710_6B5E44/SKSentimentAnalysis/sentiment_analysis_service.py\", line 17, in predict\n",
            "    series = df.iloc[0,:]\n",
            "AttributeError: 'NoneType' object has no attribute 'iloc'\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:21] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "[2021-08-26 09:57:33,863] INFO - {'service_name': 'SKSentimentAnalysis', 'service_version': '20210826093710_6B5E44', 'api': 'predict', 'task': {'data': '[\"@Karoli I firmly believe that Obama/Pelosi have ZERO desire to be civil.  It\\'s a charade and a slogan, but they want to destroy conservatism\"]', 'task_id': '4b66b447-36d1-4551-8116-e4bbc116ec94', 'batch': 1, 'http_headers': (('Host', '70a5-35-187-174-139.ngrok.io'), ('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'), ('Content-Length', '144'), ('Accept', '*/*'), ('Accept-Encoding', 'gzip, deflate'), ('Accept-Language', 'en-GB,en-US;q=0.9,en;q=0.8'), ('Content-Type', 'application/json'), ('Origin', 'http://70a5-35-187-174-139.ngrok.io'), ('Referer', 'http://70a5-35-187-174-139.ngrok.io/'), ('X-Forwarded-For', '27.7.21.82'), ('X-Forwarded-Proto', 'http'))}, 'result': {'data': '[4]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '4b66b447-36d1-4551-8116-e4bbc116ec94'}\n",
            "127.0.0.1 - - [26/Aug/2021 09:57:33] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "\n",
            "Aborted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sPoYGN61EDI",
        "outputId": "da590ded-9708-4704-d37d-f4a3f53e021f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl -i  --header \"Content-Type: application/json\"  --request POST \\ --data '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]' \\ localhost:5000/predict"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "curl: (3) Host name ' --header' contains bad letter\n",
            "curl: (3) Port number ended with ' '\n",
            "curl: (3) Host name ' --request' contains bad letter\n",
            "curl: (6) Could not resolve host: POST\n",
            "curl: (3) Host name ' --data' contains bad letter\n",
            "curl: (3) [globbing] bad range specification in column 2\n",
            "curl: (3) Host name ' localhost' contains bad letter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4u0-PCxzxiz"
      },
      "source": [
        "#### Send prediction request to REST API server\n",
        "\n",
        "Run the following command in terminal to make a HTTP request to the API server:\n",
        "```bash\n",
        "curl -i \\\n",
        "--header \"Content-Type: application/json\" \\\n",
        "--request POST \\\n",
        "--data '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]' \\\n",
        "localhost:5000/predict\n",
        "```\n",
        "\n",
        "You can also view all availabl API endpoints at [localhost:5000](localhost:5000), or look at prometheus metrics at [localhost:5000/metrics](localhost:5000/metrics) in browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzQ4cDEmzxiz"
      },
      "source": [
        "## Containerize model server with Docker\n",
        "\n",
        "\n",
        "One common way of distributing this model API server for production deployment, is via Docker containers. And BentoML provides a convenient way to do that.\n",
        "\n",
        "Note that docker is **not available in Google Colab**. You will need to download and run this notebook locally to try out this containerization with docker feature.\n",
        "\n",
        "If you already have docker configured, simply run the follow command to product a docker container serving the IrisClassifier prediction service created above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YGStuabMzxiz",
        "outputId": "bf02c74e-0b17-42c3-af5c-11922bfb5e7e"
      },
      "source": [
        "!bentoml containerize SKSentimentAnalysis:latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2020-09-22 15:19:51,428] INFO - Getting latest version SKSentimentAnalysis:20200922150740_665E0F\n",
            "\u001b[39mFound Bento: /Users/bozhaoyu/bentoml/repository/SKSentimentAnalysis/20200922150740_665E0F\u001b[0m\n",
            "[2020-09-22 15:19:51,467] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
            "[2020-09-22 15:19:51,485] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
            "\u001b[39mTag not specified, using tag parsed from BentoService: 'sksentimentanalysis:20200922150740_665E0F'\u001b[0m\n",
            "Building Docker image sksentimentanalysis:20200922150740_665E0F from SKSentimentAnalysis:latest \n",
            "-we in here\n",
            "processed docker file\n",
            "(None, None)\n",
            "root in create archive /Users/bozhaoyu/bentoml/repository/SKSentimentAnalysis/20200922150740_665E0F ['Dockerfile', 'MANIFEST.in', 'README.md', 'SKSentimentAnalysis', 'SKSentimentAnalysis/__init__.py', 'SKSentimentAnalysis/__pycache__', 'SKSentimentAnalysis/__pycache__/sentiment_analysis_service.cpython-37.pyc', 'SKSentimentAnalysis/artifacts', 'SKSentimentAnalysis/artifacts/__init__.py', 'SKSentimentAnalysis/artifacts/model.pkl', 'SKSentimentAnalysis/bentoml.yml', 'SKSentimentAnalysis/sentiment_analysis_service.py', 'bentoml-init.sh', 'bentoml.yml', 'bundled_pip_dependencies', 'bundled_pip_dependencies/BentoML-0.9.0rc0+3.gcebf2015.tar.gz', 'docker-entrypoint.sh', 'environment.yml', 'python_version', 'requirements.txt', 'setup.py']\n",
            "\b-about to build\n",
            "about to upgrade params\n",
            "check each param and update\n",
            "if use config proxy\n",
            "if buildargs\n",
            "if shmsize\n",
            "if labels\n",
            "if cache from\n",
            "if target\n",
            "if network_mode\n",
            "if squash\n",
            "if extra hosts is not None\n",
            "if platform is not None\n",
            "if isolcation is not None\n",
            "if context is not None\n",
            "setting auth {'Content-Type': 'application/tar'}\n",
            "\b-docker build <tempfile._TemporaryFileWrapper object at 0x7fd1f74b5e10> {'t': 'sksentimentanalysis:20200922150740_665E0F', 'remote': None, 'q': False, 'nocache': False, 'rm': False, 'forcerm': False, 'pull': False, 'dockerfile': (None, None)}\n",
            "\b\\docker response <Response [200]>\n",
            "context closes\n",
            "\b-print responses\n",
            "\u001b[39mStep 1/15 : FROM bentoml/model-server:0.9.0.pre\u001b[0m\n",
            "\u001b[39m ---> a25066aa8b0e\u001b[0m\n",
            "\u001b[39mStep 2/15 : ARG EXTRA_PIP_INSTALL_ARGS=\u001b[0m\n",
            "\u001b[39m ---> Using cache\u001b[0m\n",
            "\u001b[39m ---> fc6e47d06522\u001b[0m\n",
            "\u001b[39mStep 3/15 : ENV EXTRA_PIP_INSTALL_ARGS $EXTRA_PIP_INSTALL_ARGS\u001b[0m\n",
            "\u001b[39m ---> Using cache\u001b[0m\n",
            "\u001b[39m ---> db8172e98571\u001b[0m\n",
            "\u001b[39mStep 4/15 : COPY environment.yml requirements.txt setup.sh* bentoml-init.sh python_version* /bento/\u001b[0m\n",
            "\b/\u001b[39m ---> 5e0bc38fd307\u001b[0m\n",
            "\u001b[39mStep 5/15 : WORKDIR /bento\u001b[0m\n",
            "\b|\u001b[39m ---> Running in 8c9ef32e7373\u001b[0m\n",
            "\b\\\u001b[39m ---> 0121cd695e1b\u001b[0m\n",
            "\u001b[39mStep 6/15 : RUN chmod +x /bento/bentoml-init.sh\u001b[0m\n",
            "\b-\u001b[39m ---> Running in 84140eab64ba\u001b[0m\n",
            "\b|\u001b[39m ---> 577a4d986fdf\u001b[0m\n",
            "\u001b[39mStep 7/15 : RUN if [ -f /bento/bentoml-init.sh ]; then bash -c /bento/bentoml-init.sh; fi\u001b[0m\n",
            "\b\\\u001b[39m ---> Running in 595753551a03\u001b[0m\n",
            "\b\\\u001b[39m\u001b[91m+++ dirname /bento/bentoml-init.sh\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[39m\u001b[91m++ cd /bento\n",
            "++ pwd -P\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[39m\u001b[91m+ SAVED_BUNDLE_PATH=/bento\n",
            "+ cd /bento\n",
            "+ '[' -f ./setup.sh ']'\n",
            "+ '[' -f ./python_version ']'\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[39m\u001b[91m++ cat ./python_version\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[39m\u001b[91m+ PY_VERSION_SAVED=3.7.3\n",
            "+ DESIRED_PY_VERSION=3.7\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[39m\u001b[91m++ python -c 'import sys; print(f\"{sys.version_info.major}.{sys.version_info.minor}\")'\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[39mPython Version in docker base image 3.7 matches requirement python=3.7. Skipping.\n",
            "Updating conda base environment with environment.yml\u001b[0m\n",
            "\u001b[39m\u001b[91m+ CURRENT_PY_VERSION=3.7\n",
            "+ [[ 3.7 == \\3\\.\\7 ]]\n",
            "+ echo 'Python Version in docker base image 3.7 matches requirement python=3.7. Skipping.'\n",
            "+ command -v conda\n",
            "+ echo 'Updating conda base environment with environment.yml'\n",
            "+ conda env update -n base -f ./environment.yml\n",
            "\u001b[0m\u001b[0m\n",
            "\b-\u001b[39mCollecting package metadata (repodata.json): ...working... \u001b[0m\n",
            "\b/\u001b[39mdone\u001b[0m\n",
            "\u001b[39mSolving environment: ...working... \u001b[0m\n",
            "\b\\\u001b[39mdone\u001b[0m\n",
            "\b-\u001b[39m\n",
            "Downloading and Extracting Packages\n",
            "openssl-1.1.1h       | 2.1 MB    |            |   0% \u001b[0m\n",
            "openssl-1.1.1h       | 2.1 MB    |            |   1% \u001b[0m\n",
            "openssl-1.1.1h       | 2.1 MB    | ###3       |  34% \u001b[0m\n",
            "openssl-1.1.1h       | 2.1 MB    | ########5  |  85% \u001b[0m\n",
            "openssl-1.1.1h       | 2.1 MB    | ########## | 100% \u001b[0m\n",
            "\u001b[39m\n",
            "certifi-2020.6.20    | 151 KB    |            |   0% \u001b[0m\n",
            "certifi-2020.6.20    | 151 KB    | ########## | 100% \u001b[0m\n",
            "\u001b[39m\n",
            "pip-20.2.3           | 1.1 MB    |            |   0% \u001b[0m\n",
            "pip-20.2.3           | 1.1 MB    | #######    |  70% \u001b[0m\n",
            "pip-20.2.3           | 1.1 MB    | ########## | 100% \u001b[0m\n",
            "pip-20.2.3           | 1.1 MB    | ########## | 100% \u001b[0m\n",
            "\u001b[39m\n",
            "python_abi-3.7       | 4 KB      |            |   0% \u001b[0m\n",
            "python_abi-3.7       | 4 KB      | ########## | 100% \u001b[0m\n",
            "\u001b[39m\n",
            "ca-certificates-2020 | 145 KB    |            |   0% \u001b[0m\n",
            "ca-certificates-2020 | 145 KB    | ########## | 100% \u001b[0m\n",
            "\u001b[39m\n",
            "readline-8.0         | 281 KB    |            |   0% \u001b[0m\n",
            "readline-8.0         | 281 KB    | ########## | 100% \u001b[0m\n",
            "readline-8.0         | 281 KB    | ########## | 100% \u001b[0m\n",
            "\u001b[39m\n",
            "python-3.7.9         | 45.3 MB   |            |   0% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   |            |   0% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | 1          |   2% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | 3          |   3% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | 4          |   5% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | 6          |   7% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | 8          |   8% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | 9          |  10% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #1         |  11% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #2         |  13% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #4         |  15% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #6         |  17% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #8         |  19% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ##         |  20% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ##2        |  23% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ##5        |  25% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ##7        |  28% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ###        |  30% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ###2       |  32% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ###4       |  35% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ###8       |  38% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ####2      |  42% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ####5      |  45% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ####8      |  49% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #####2     |  52% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #####5     |  55% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #####8     |  59% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ######2    |  62% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ######5    |  65% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ######8    |  68% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #######    |  71% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #######3   |  73% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #######6   |  77% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #######9   |  80% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ########3  |  83% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ########6  |  86% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #########  |  91% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #########5 |  95% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | #########8 |  99% \u001b[0m\n",
            "python-3.7.9         | 45.3 MB   | ########## | 100% \n",
            "Preparing transaction: ...working... \u001b[0m\n",
            "\b/\u001b[39mdone\u001b[0m\n",
            "\u001b[39mVerifying transaction: \u001b[0m\n",
            "\u001b[39m...working... \u001b[0m\n",
            "\b-\u001b[39mdone\u001b[0m\n",
            "\u001b[39mExecuting transaction: ...working... \u001b[0m\n",
            "\b|\u001b[39mdone\u001b[0m\n",
            "\b|\u001b[39m#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate base\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\u001b[0m\n",
            "\b\\\u001b[39m\u001b[91m+ pip install -r ./requirements.txt --no-cache-dir\n",
            "\u001b[0m\u001b[0m\n",
            "\b/\u001b[39mRequirement already satisfied: bentoml==0.9.0.pre in /opt/conda/lib/python3.7/site-packages (from -r ./requirements.txt (line 1)) (0.9.0rc0)\u001b[0m\n",
            "\b\\\u001b[39mCollecting scikit-learn==0.23.0\u001b[0m\n",
            "\b-\u001b[39m  Downloading scikit_learn-0.23.0-cp37-cp37m-manylinux1_x86_64.whl (7.3 MB)\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\\\u001b[39mCollecting pandas==0.24.2\u001b[0m\n",
            "\u001b[39m  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\u001b[0m\n",
            "\b/\u001b[39mRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.13.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: ruamel.yaml>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.15.87)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.19.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: gunicorn in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (20.0.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: py-zipkin in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.20.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: cerberus in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.3.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2020.6.20)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.24.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (20.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: alembic in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.4.3)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: humanfriendly in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (8.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.8.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: multidict in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (4.7.6)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (7.1.2)\u001b[0m\n",
            "\b|\u001b[39mRequirement already satisfied: flask in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: sqlalchemy-utils<0.36.8 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.36.7)\u001b[0m\n",
            "\b\\\u001b[39mRequirement already satisfied: configparser in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (5.0.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.8.7)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: python-json-logger in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.1.11)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.15.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.3.19)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: docker in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (4.3.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: grpcio<=1.27.2 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.27.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (5.7.2)\u001b[0m\n",
            "\b-\u001b[39mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.6.2)\u001b[0m\n",
            "\u001b[39mCollecting threadpoolctl>=2.0.0\u001b[0m\n",
            "\b/\u001b[39m  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\u001b[0m\n",
            "\b|\u001b[39mCollecting joblib>=0.11\u001b[0m\n",
            "\u001b[39m  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\u001b[0m\n",
            "\b|\u001b[39mCollecting scipy>=0.19.1\u001b[0m\n",
            "\u001b[39m  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\u001b[0m\n",
            "\b|\u001b[39mCollecting pytz>=2011k\u001b[0m\n",
            "\b\\\u001b[39m  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (49.6.0.post20200814)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: thriftpy2>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from py-zipkin->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.4.11)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.10)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.25.10)\u001b[0m\n",
            "\b-\u001b[39mRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.0.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.3)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.11.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: botocore<1.19.0,>=1.18.2 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.18.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.3.3)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.57.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (20.2.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.5.1)\u001b[0m\n",
            "\b/\u001b[39mRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.0.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: ply<4.0,>=3.4 in /opt/conda/lib/python3.7/site-packages (from thriftpy2>=0.4.0->py-zipkin->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.11)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.1)\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[39mRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.7.4.3)\u001b[0m\n",
            "\b|\u001b[39mInstalling collected packages: threadpoolctl, joblib, scipy, scikit-learn, pytz, pandas\u001b[0m\n",
            "\b/\u001b[39mSuccessfully installed joblib-0.16.0 pandas-0.24.2 pytz-2020.1 scikit-learn-0.23.0 scipy-1.5.2 threadpoolctl-2.1.0\u001b[0m\n",
            "\b-\u001b[39m ---> 46ea3f6e2f1a\u001b[0m\n",
            "\u001b[39mStep 8/15 : COPY . /bento\u001b[0m\n",
            "\b\\\u001b[39m ---> a21c7871ef61\u001b[0m\n",
            "\u001b[39mStep 9/15 : RUN if [ -d /bento/bundled_pip_dependencies ]; then pip install -U bundled_pip_dependencies/* ;fi\u001b[0m\n",
            "\b-\u001b[39m ---> Running in 9e7480b0a9a0\u001b[0m\n",
            "\b|\u001b[39mProcessing ./bundled_pip_dependencies/BentoML-0.9.0rc0+3.gcebf2015.tar.gz\u001b[0m\n",
            "\b|\u001b[39m  Installing build dependencies: started\u001b[0m\n",
            "\b\\\u001b[39m  Installing build dependencies: finished with status 'done'\u001b[0m\n",
            "\u001b[39m  Getting requirements to build wheel: started\u001b[0m\n",
            "\b/\u001b[39m  Getting requirements to build wheel: finished with status 'done'\u001b[0m\n",
            "\u001b[39m    Preparing wheel metadata: started\u001b[0m\n",
            "\b\\\u001b[39m    Preparing wheel metadata: finished with status 'done'\u001b[0m\n",
            "\b/\u001b[39mRequirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (3.13.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: prometheus-client in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.8.0)\u001b[0m\n",
            "\b|\u001b[39mRequirement already satisfied, skipping upgrade: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.3.19)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (20.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: docker in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (4.3.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: python-json-logger in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.1.11)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: gunicorn in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (20.0.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: grpcio<=1.27.2 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.27.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: flask in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.1.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: ruamel.yaml>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.15.87)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: psutil in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (5.7.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: sqlalchemy-utils<0.36.8 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.36.7)\u001b[0m\n",
            "\b\\\u001b[39mRequirement already satisfied, skipping upgrade: cerberus in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.3.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: tabulate in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.8.7)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (7.1.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (2.8.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: multidict in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (4.7.6)\u001b[0m\n",
            "\b-\u001b[39mRequirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (2.24.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: configparser in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (5.0.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.19.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (2020.6.20)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: boto3 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.15.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: alembic in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.4.3)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: py-zipkin in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.20.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: humanfriendly in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (8.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: aiohttp in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (3.6.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->BentoML==0.9.0rc0+3.gcebf2015) (49.6.0.post20200814)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->BentoML==0.9.0rc0+3.gcebf2015) (1.15.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->BentoML==0.9.0rc0+3.gcebf2015) (2.4.7)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker->BentoML==0.9.0rc0+3.gcebf2015) (0.57.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.9.0rc0+3.gcebf2015) (2.11.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.9.0rc0+3.gcebf2015) (1.1.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.9.0rc0+3.gcebf2015) (1.0.1)\u001b[0m\n",
            "\b/\u001b[39mRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.9.0rc0+3.gcebf2015) (3.0.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.9.0rc0+3.gcebf2015) (2.10)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.9.0rc0+3.gcebf2015) (1.25.10)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: botocore<1.19.0,>=1.18.2 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.9.0rc0+3.gcebf2015) (1.18.2)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.9.0rc0+3.gcebf2015) (0.10.0)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.9.0rc0+3.gcebf2015) (0.3.3)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->BentoML==0.9.0rc0+3.gcebf2015) (1.0.4)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->BentoML==0.9.0rc0+3.gcebf2015) (1.1.3)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: thriftpy2>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from py-zipkin->BentoML==0.9.0rc0+3.gcebf2015) (0.4.11)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (3.0.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (20.2.0)\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[39mRequirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (1.5.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask->BentoML==0.9.0rc0+3.gcebf2015) (1.1.1)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: ply<4.0,>=3.4 in /opt/conda/lib/python3.7/site-packages (from thriftpy2>=0.4.0->py-zipkin->BentoML==0.9.0rc0+3.gcebf2015) (3.11)\u001b[0m\n",
            "\u001b[39mRequirement already satisfied, skipping upgrade: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (3.7.4.3)\u001b[0m\n",
            "\u001b[39mBuilding wheels for collected packages: BentoML\u001b[0m\n",
            "\u001b[39m  Building wheel for BentoML (PEP 517): started\u001b[0m\n",
            "\b\\\u001b[39m  Building wheel for BentoML (PEP 517): finished with status 'done'\u001b[0m\n",
            "\u001b[39m  Created wheel for BentoML: filename=BentoML-0.9.0rc0+3.gcebf2015-py3-none-any.whl size=3064091 sha256=6ecc0cd97b1040685993d1442b121c6673cf956bb30836265b35a79aae78a9d3\u001b[0m\n",
            "\u001b[39m  Stored in directory: /root/.cache/pip/wheels/a0/45/41/62152db705af4ff47e7a3d6abf6247986eef4aa1b94a58d3b9\u001b[0m\n",
            "\u001b[39mSuccessfully built BentoML\u001b[0m\n",
            "\b\\\u001b[39mInstalling collected packages: BentoML\n",
            "  Attempting uninstall: BentoML\u001b[0m\n",
            "\u001b[39m    Found existing installation: BentoML 0.9.0rc0\u001b[0m\n",
            "\b|\u001b[39m    Uninstalling BentoML-0.9.0rc0:\u001b[0m\n",
            "\b-\u001b[39m      Successfully uninstalled BentoML-0.9.0rc0\u001b[0m\n",
            "\b|\u001b[39mSuccessfully installed BentoML-0.9.0rc0+3.gcebf2015\u001b[0m\n",
            "\b/\u001b[39m ---> bb136663f2f0\u001b[0m\n",
            "\u001b[39mStep 10/15 : ENV PORT 5000\u001b[0m\n",
            "\b\\\u001b[39m ---> Running in c66e6adb4b02\u001b[0m\n",
            "\b-\u001b[39m ---> a24979b816f6\u001b[0m\n",
            "\u001b[39mStep 11/15 : EXPOSE $PORT\u001b[0m\n",
            "\b/\u001b[39m ---> Running in faf5205f58c9\u001b[0m\n",
            "\b\\\u001b[39m ---> 4d063d715dc8\u001b[0m\n",
            "\u001b[39mStep 12/15 : COPY docker-entrypoint.sh /usr/local/bin/\u001b[0m\n",
            "\b-\u001b[39m ---> 5c6324035146\u001b[0m\n",
            "\u001b[39mStep 13/15 : RUN chmod +x /usr/local/bin/docker-entrypoint.sh\u001b[0m\n",
            "\b/\u001b[39m ---> Running in 26e6fc37f203\u001b[0m\n",
            "\b/\u001b[39m ---> 54617b3a1a63\u001b[0m\n",
            "\u001b[39mStep 14/15 : ENTRYPOINT [ \"docker-entrypoint.sh\" ]\u001b[0m\n",
            "\b|\u001b[39m ---> Running in b3a775b848aa\u001b[0m\n",
            "\b\\\u001b[39m ---> 1ce8ea3d0b7a\u001b[0m\n",
            "\u001b[39mStep 15/15 : CMD [\"bentoml\", \"serve-gunicorn\", \"/bento\"]\u001b[0m\n",
            "\b-\u001b[39m ---> Running in 5c88bc6f5d7d\u001b[0m\n",
            "\b/\u001b[39m ---> 1ef09528851b\u001b[0m\n",
            "\b|\u001b[39mSuccessfully built 1ef09528851b\u001b[0m\n",
            "\u001b[39mSuccessfully tagged sksentimentanalysis:20200922150740_665E0F\u001b[0m\n",
            "\u001b[32mFinished building sksentimentanalysis:20200922150740_665E0F from SKSentimentAnalysis:latest\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycMM-W8ozxi0",
        "outputId": "cb9b821b-149b-4c96-fca8-92ae6200a14f"
      },
      "source": [
        "!docker run -p 5000:5000 sksentimentanalysis:20200922150740_665E0F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2020-09-22 22:24:57,127] INFO - Starting BentoML API server in production mode..\n",
            "[2020-09-22 22:24:57,567] INFO - get_gunicorn_num_of_workers: 3, calculated by cpu count\n",
            "[2020-09-22 22:24:57 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
            "[2020-09-22 22:24:57 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
            "[2020-09-22 22:24:57 +0000] [1] [INFO] Using worker: sync\n",
            "[2020-09-22 22:24:57 +0000] [11] [INFO] Booting worker with pid: 11\n",
            "[2020-09-22 22:24:57 +0000] [12] [INFO] Booting worker with pid: 12\n",
            "[2020-09-22 22:24:57 +0000] [13] [INFO] Booting worker with pid: 13\n",
            "[2020-09-22 22:24:57,849] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2020-09-22 22:24:57,849] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2020-09-22 22:24:57,878] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
            "[2020-09-22 22:24:57,878] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.3, but current environment version is 3.7.9.\n",
            "[2020-09-22 22:24:57,879] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
            "[2020-09-22 22:24:57,880] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.3, but current environment version is 3.7.9.\n",
            "[2020-09-22 22:24:57,906] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2020-09-22 22:24:57,931] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
            "[2020-09-22 22:24:57,932] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.3, but current environment version is 3.7.9.\n",
            "[2020-09-22 22:24:58,365] WARNING - bentoml.handlers.* will be deprecated after BentoML 1.0, use bentoml.adapters.* instead\n",
            "[2020-09-22 22:24:58,365] WARNING - bentoml.handlers.* will be deprecated after BentoML 1.0, use bentoml.adapters.* instead\n",
            "[2020-09-22 22:24:58,365] WARNING - bentoml.handlers.* will be deprecated after BentoML 1.0, use bentoml.adapters.* instead\n",
            "^C\n",
            "[2020-09-22 22:25:07 +0000] [23] [INFO] Booting worker with pid: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpkjfrTuzxi0"
      },
      "source": [
        "## Load saved BentoService\n",
        "\n",
        "bentoml.load is the API for loading a BentoML packaged model in python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "1YK1wAWnzxi0",
        "outputId": "f364a296-fec0-4b64-bb30-6616f7f0ab96"
      },
      "source": [
        "import bentoml\n",
        "import pandas as pd\n",
        "\n",
        "# Load exported bentoML model archive from path\n",
        "loaded_bento_service = bentoml.load(saved_path)\n",
        "\n",
        "# Call predict on the restored sklearn model\n",
        "loaded_bento_service.predict(pd.DataFrame(data=[\"good\", \"great\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2020-09-22 15:26:45,311] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
            "[2020-09-22 15:26:45,313] WARNING - Module `sentiment_analysis_service` already loaded, using existing imported module.\n",
            "[2020-09-22 15:26:46,636] WARNING - pip package requirement pandas already exist\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUAoVjAzxi1"
      },
      "source": [
        "## Launch inference job from CLI\n",
        "\n",
        "BentoML cli supports loading and running a packaged model from CLI. With the DataframeInput adapter, the CLI command supports reading input Dataframe data from CLI argument or local csv or json files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExZxSRSPzxi1",
        "outputId": "f148024f-e7c9-4a05-f6a0-51b267ac850b"
      },
      "source": [
        "!bentoml run SKSentimentAnalysis:latest predict \\\n",
        "--input '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2020-09-22 15:25:33,640] INFO - Getting latest version SKSentimentAnalysis:20200922150740_665E0F\n",
            "[2020-09-22 15:25:33,681] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
            "[2020-09-22 15:25:33,698] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
            "[2020-09-22 15:25:34,152] WARNING - bentoml.handlers.* will be deprecated after BentoML 1.0, use bentoml.adapters.* instead\n",
            "[2020-09-22 15:25:34,544] INFO - Using default docker base image: `None` specified inBentoML config file or env var. User must make sure that the docker base image either has Python 3.7 or conda installed.\n",
            "[2020-09-22 15:25:38,102] WARNING - pip package requirement pandas already exist\n",
            "[2020-09-22 15:25:44,431] INFO - {'service_name': 'SKSentimentAnalysis', 'service_version': '20200922150740_665E0F', 'api': 'predict', 'task': {'data': {}, 'task_id': 'd5aebb09-b388-4e19-8a9f-2a364da90a54', 'batch': 3, 'cli_args': ('--input', '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]')}, 'result': {'data': '[4, 4, 4]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': 'd5aebb09-b388-4e19-8a9f-2a364da90a54'}\n",
            "[4, 4, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2dUcVF7zxi1"
      },
      "source": [
        "# Deployment Options\n",
        "\n",
        "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
        "- [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
        "- [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
        "- [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
        "\n",
        "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
        "- [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
        "- [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
        "- [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
        "- [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
        "\n",
        "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
        "- [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
        "- [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
        "- [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
        "- [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
        "- [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlVWIqsNzxi1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}